{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66a03373",
   "metadata": {},
   "source": [
    "# 4.1. OLS model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21835a3",
   "metadata": {},
   "source": [
    "## 4.1.1. Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047e3c0f",
   "metadata": {},
   "source": [
    "### Preprocessing module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20adcef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "CURRENT_YEAR = 2025\n",
    "MODEL_REF_PRICE_PATH = \"../data/raw/model_ref_price_full.csv\"\n",
    "MODEL_REF_EXTRA_PRICE_PATH = \"../data/raw/model_ref_price_extra.csv\"\n",
    "COUNTRY_MULTIPLIER_PATH = \"../data/raw/origin_country_multiplier.csv\"\n",
    "SCOLI_PATH = \"../data/raw/input_scoli_2023.json\"\n",
    "\n",
    "\n",
    "def read_json_stat(file_path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Read a JSON-stat file as an input and return a parsed Dataframe\n",
    "    \"\"\"\n",
    "    with open(file_path, encoding=\"utf-8\") as input_file:\n",
    "        data = json.load(input_file)\n",
    "\n",
    "    # Extracting the dimensions and values\n",
    "    dimensions = data[\"dataset\"][\"dimension\"]\n",
    "    values = data[\"dataset\"][\"value\"]\n",
    "\n",
    "    # Creating a list of headers for the DataFrame\n",
    "    headers = [dimensions[dim][\"label\"] for dim in dimensions[\"id\"]] + [\"Value\"]\n",
    "\n",
    "    # Creating a list of rows for the DataFrame\n",
    "    rows = []\n",
    "    for i, value in enumerate(values):\n",
    "        row = []\n",
    "        for dim in dimensions[\"id\"]:\n",
    "            for key, index in dimensions[dim][\"category\"][\"index\"].items():\n",
    "                if index == i % dimensions[\"size\"][dimensions[\"id\"].index(dim)]:\n",
    "                    row.append(dimensions[dim][\"category\"][\"label\"][key])\n",
    "        row.append(value)\n",
    "        rows.append(row)\n",
    "\n",
    "    # Creating the DataFrame\n",
    "    df = pd.DataFrame(rows, columns=headers)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def transform_mileage(df_col: pd.Series) -> pd.Series:\n",
    "    df = df_col.to_frame()\n",
    "    df[\"mileage\"] = df.iloc[:, 0]\n",
    "    df[\"mileage_log\"] = np.log(df[\"mileage\"])\n",
    "    return df[\"mileage_log\"]\n",
    "\n",
    "\n",
    "def transform_model(df_col: pd.Series) -> pd.Series:\n",
    "    # Get reference value\n",
    "    df_variants = pd.read_csv(MODEL_REF_PRICE_PATH)\n",
    "    df_model_extra = pd.read_csv(MODEL_REF_EXTRA_PRICE_PATH)\n",
    "\n",
    "    # Filter out null price\n",
    "    df_variants.dropna(subset=\"price_min\", inplace=True)\n",
    "\n",
    "    # Get mean price\n",
    "    df_variants[\"price_avg\"] = (df_variants[\"price_min\"] + df_variants[\"price_max\"]) / 2\n",
    "\n",
    "    # Get model. Resolve case with 'Air Blade'\n",
    "    df_variants[\"model_original\"] = (\n",
    "        df_variants[\"model_name\"].str.split().apply(lambda x: x[0])\n",
    "    )\n",
    "    df_variants[\"model\"] = df_variants[\"model_original\"].case_when(\n",
    "        caselist=[\n",
    "            (df_variants[\"model_name\"].str.contains(\"Air Blade\"), \"Air Blade\"),\n",
    "            (df_variants[\"model_name\"].str.contains(\"SH Mode\"), \"SH Mode\"),\n",
    "            (df_variants[\"model_name\"].str.contains(\"Super Cub\"), \"Cub\"),\n",
    "            (df_variants[\"model_name\"].str.contains(\"Winner X\"), \"Winner X\"),\n",
    "            (df_variants[\"brand_name\"].eq(\"Vespa\"), \"Vespa\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Get average price by model\n",
    "    df_model_ref_price_original = df_variants.groupby(by=\"model\", as_index=False).agg(\n",
    "        {\"price_avg\": \"mean\"}\n",
    "    )\n",
    "    df_model_ref_price = pd.concat([df_model_ref_price_original, df_model_extra])\n",
    "    df_model_ref_price[\"price_avg_log\"] = np.log(\n",
    "        df_model_ref_price[\"price_avg\"] * 1_000\n",
    "    )\n",
    "\n",
    "    # Join with dataframe\n",
    "    df = df_col.to_frame()\n",
    "    df[\"model\"] = df.iloc[:, 0]\n",
    "\n",
    "    output_df = df.merge(\n",
    "        right=df_model_ref_price, left_on=\"model\", right_on=\"model\", how=\"left\"\n",
    "    )\n",
    "\n",
    "    return output_df[\"price_avg_log\"]\n",
    "\n",
    "\n",
    "def transform_origin(df_col: pd.Series) -> pd.Series:\n",
    "    # Get reference value\n",
    "    df_countries = pd.read_csv(COUNTRY_MULTIPLIER_PATH)\n",
    "\n",
    "    # Join with dataframe\n",
    "    df = df_col.to_frame()\n",
    "    df[\"origin\"] = df.iloc[:, 0]\n",
    "    output_df = df.merge(\n",
    "        right=df_countries, left_on=\"origin\", right_on=\"country_name\", how=\"left\"\n",
    "    )\n",
    "\n",
    "    # Check for nan values\n",
    "    count_nan_value = int(output_df[\"country_multiplier\"].isnull().sum())\n",
    "    if count_nan_value > 0:\n",
    "        logging.error(\n",
    "            f\"There are nan values: {output_df[output_df['country_multiplier'].isnull()]}\"\n",
    "        )\n",
    "        raise ValueError(f\"Found {count_nan_value} nan values\")\n",
    "\n",
    "    return output_df[\"country_multiplier\"]\n",
    "\n",
    "\n",
    "def transform_province(df_col: pd.Series) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Note that the input here must be picked from the input_scoli itself,\n",
    "    otherwise join will introduce nan values\n",
    "    \"\"\"\n",
    "    # Get reference value\n",
    "    df_scoli = read_json_stat(file_path=SCOLI_PATH)\n",
    "    df_scoli.columns = [\"province\", \"year\", \"province_scoli\"]\n",
    "\n",
    "    # Join with dataframe\n",
    "    df = df_col.to_frame()\n",
    "    df[\"province\"] = df.iloc[:, 0]\n",
    "    output_df = df.merge(\n",
    "        right=df_scoli, left_on=\"province\", right_on=\"province\", how=\"left\"\n",
    "    )\n",
    "\n",
    "    # Check for nan values\n",
    "    count_nan_value = int(output_df[\"province_scoli\"].isnull().sum())\n",
    "    if count_nan_value > 0:\n",
    "        logging.error(\n",
    "            f\"There are nan values: {output_df[output_df['province_scoli'].isnull()]}\"\n",
    "        )\n",
    "        raise ValueError(f\"Found {count_nan_value} nan values\")\n",
    "\n",
    "    return output_df[\"province_scoli\"]\n",
    "\n",
    "\n",
    "def transform_reg_year(df_col: pd.Series) -> pd.Series:\n",
    "    # Read column\n",
    "    df = df_col.to_frame()\n",
    "    df[\"reg_year\"] = df.iloc[:, 0]\n",
    "    df[\"age\"] = CURRENT_YEAR - df[\"reg_year\"]\n",
    "\n",
    "    # Move age = 0 to age = 0.5 since the bike must have some age\n",
    "    df[\"age_updated\"] = df[\"age\"].case_when(caselist=[(df[\"age\"].eq(0), 0.5)])\n",
    "\n",
    "    df[\"age_log\"] = np.log(df[\"age_updated\"])\n",
    "\n",
    "    return df[\"age_log\"]\n",
    "\n",
    "\n",
    "def transform_prediction_input(input: dict) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Transform inputs from user and output as the model input\n",
    "    Input should have these fields:\n",
    "    - mileage\n",
    "    - model\n",
    "    - origin\n",
    "    - province\n",
    "    - reg_year\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame(input)\n",
    "    df[\"age_log\"] = transform_reg_year(df_col=df[\"reg_year\"])\n",
    "    df[\"mileage_log\"] = transform_mileage(df_col=df[\"mileage\"])\n",
    "    df[\"origin_multiplier\"] = transform_origin(df_col=df[\"origin\"])\n",
    "    df[\"model_ref_price_log\"] = transform_model(df_col=df[\"model\"])\n",
    "    df[\"province_scoli\"] = transform_province(df_col=df[\"province\"])\n",
    "\n",
    "    X = sm.add_constant(\n",
    "        data=df[\n",
    "            [\n",
    "                \"age_log\",\n",
    "                \"mileage_log\",\n",
    "                \"origin_multiplier\",\n",
    "                \"model_ref_price_log\",\n",
    "                # \"province_scoli\",\n",
    "            ]\n",
    "        ],\n",
    "        has_constant=\"add\",\n",
    "    )\n",
    "\n",
    "    return X\n",
    "\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred, axis: int = None):\n",
    "    \"\"\"\n",
    "    Ref:\n",
    "    - https://stackoverflow.com/questions/55996319/my-mape-mean-absolute-percentage-error-function-returns-a-number-over-100-when\n",
    "    - https://www.statsmodels.org/dev/_modules/statsmodels/tools/eval_measures.html#meanabs\n",
    "\n",
    "    Returns: percentage without multiplying with 100\n",
    "    \"\"\"\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true), axis=axis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75d4ed0",
   "metadata": {},
   "source": [
    "### Prepare data for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e75c7d23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Thac si\\02_Phat trien phan mem nang cao\\khdl2024-ptpm-gia-xe-cu\\.venv\\Lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "d:\\Thac si\\02_Phat trien phan mem nang cao\\khdl2024-ptpm-gia-xe-cu\\.venv\\Lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from statsmodels.tools.eval_measures import meanabs, mse, rmse\n",
    "\n",
    "INPUT_FILE_PATH = \"../data/raw/chotot_data.csv\"\n",
    "ORIGIN_MAPPING = {\n",
    "    \"Thái Lan\": [\"thái\", \"thai lan\", \"xe thái\"],\n",
    "    \"Nhật Bản\": [\"nhật\", \"nhat ban\", \"xe nhật\"],\n",
    "    \"Indonesia\": [\"indonesia\", \"xe indo\"],\n",
    "    \"Ý\": [\"ý\", \"italia\"],\n",
    "    \"Mỹ\": [\"mỹ\", \"america\", \"xe mỹ\"],\n",
    "    \"Trung Quốc\": [\"trung\", \"xe tq\", \"xe trung quốc\", \"trung quốc\"],\n",
    "    \"Ấn Độ\": [\"ấn\", \"xe ấn\", \"an do\"],\n",
    "    \"Hàn Quốc\": [\"hàn\", \"xe hàn\", \"han quoc\"],\n",
    "    \"Đức\": [\"đức\", \"xe đức\", \"duc\"],\n",
    "    \"Đài Loan\": [\"đài\", \"xe đài\", \"dai loan\"],\n",
    "}\n",
    "\n",
    "# Config pandas\n",
    "pd.options.mode.copy_on_write = True\n",
    "\n",
    "df = pd.read_csv(INPUT_FILE_PATH)\n",
    "\n",
    "# Clean columns\n",
    "df[\"price_clean\"] = pd.to_numeric(df[\"price\"].str.replace(\"đ\", \"\").str.replace(\".\", \"\"))\n",
    "df[\"province\"] = df[\"location\"].str.split(\", \").apply(lambda x: x[-1])\n",
    "df[\"province_clean\"] = df[\"province\"].case_when(\n",
    "    caselist=[\n",
    "        (df[\"province\"].eq(\"Tp Hồ Chí Minh\"), \"TP. Hồ Chí Minh\"),\n",
    "        (df[\"province\"].eq(\"Bà Rịa - Vũng Tàu\"), \"Bà Rịa-Vũng Tàu\"),\n",
    "        (df[\"province\"].eq(\"Thừa Thiên Huế\"), \"Thừa Thiên - Huế\"),\n",
    "        (df[\"province\"].eq(\"Thanh Hóa\"), \"Thanh Hoá\"),\n",
    "        (df[\"province\"].eq(\"Khánh Hòa\"), \"Khánh Hoà\"),\n",
    "        (df[\"province\"].eq(\"Hòa Bình\"), \"Hoà Bình\"),\n",
    "    ]\n",
    ")\n",
    "df[\"reg_year_clean\"] = pd.to_numeric(\n",
    "    df[\"reg_year\"].case_when(caselist=[(df[\"reg_year\"].eq(\"trước năm 1980\"), 1980)])\n",
    ")\n",
    "\n",
    "\n",
    "# Update origin from description and title\n",
    "def update_origin(row):\n",
    "    if row[\"origin\"].lower() in [\"đang cập nhật\", \"nước khác\"]:\n",
    "        text = f\"{row['description']} {row['title']}\".lower().strip()\n",
    "        for country, keywords in ORIGIN_MAPPING.items():\n",
    "            if any(re.search(rf\"\\b{keyword}\\b\", text) for keyword in keywords):\n",
    "                return country\n",
    "        return \"Việt Nam\"\n",
    "    else:\n",
    "        return row[\"origin\"]\n",
    "\n",
    "\n",
    "df[\"origin_updated\"] = df.apply(update_origin, axis=1)\n",
    "\n",
    "# Reduce scale of price and transform to log\n",
    "df[\"price_clean\"] = df[\"price_clean\"] / 1_000\n",
    "df[\"price_log\"] = np.log(df[\"price_clean\"])\n",
    "\n",
    "\n",
    "# Transform columns into suitable predictors\n",
    "# Note that this operation should be done before filter, since\n",
    "# filter will remove some indexes. Some transforms use merge, which\n",
    "# reset index, making the output becomes difficult to understand.\n",
    "df[\"mileage_log\"] = transform_mileage(df[\"mileage\"])\n",
    "df[\"model_ref_price_log\"] = transform_model(df[\"model\"])\n",
    "df[\"origin_multiplier\"] = transform_origin(df[\"origin_updated\"])\n",
    "df[\"province_scoli\"] = transform_province(df[\"province_clean\"])\n",
    "df[\"age_log\"] = transform_reg_year(df[\"reg_year_clean\"])\n",
    "\n",
    "\n",
    "# Filter\n",
    "\n",
    "## Remove vague models\n",
    "df_filter = df[~df[\"model\"].isin([\"Dòng khác\", \"dòng khác\"])]\n",
    "\n",
    "## Price should be at least 1M. Look at offers at 600M maximum\n",
    "df_filter = df_filter[\n",
    "    df_filter[\"price_clean\"].between(1_000, 600_000, inclusive=\"neither\")\n",
    "]\n",
    "\n",
    "## Get rows with reference price only\n",
    "df_filter = df_filter[df_filter[\"model_ref_price_log\"].notnull()]\n",
    "\n",
    "\n",
    "# Models with over 30 offers only\n",
    "df_model_count = df_filter.groupby(\"model\").agg(counts=(\"model\", \"count\")).reset_index()\n",
    "\n",
    "## Remove outliers, unreasonable price. These are either\n",
    "## only the bike component, or are actually another model\n",
    "df_filter = df_filter[\n",
    "    ~((df_filter[\"model\"] == \"SH\") & (df_filter[\"price_clean\"] < 3_000))\n",
    "]\n",
    "\n",
    "# df_filter = df_filter[~df_filter[\"model\"].isin([\"Vespa\", \"Cub\", \"R\", \"Dream\"])]\n",
    "\n",
    "\n",
    "## Try keeping records with sensible mileage\n",
    "df_filter = df_filter[df_filter[\"mileage\"].between(500, 900_000)]\n",
    "\n",
    "# Linear regression models\n",
    "Y = df_filter[\"price_log\"]\n",
    "X1 = sm.add_constant(\n",
    "    data=df_filter[\n",
    "        [\n",
    "            \"age_log\",\n",
    "            \"mileage_log\",\n",
    "            \"origin_multiplier\",\n",
    "            \"model_ref_price_log\",\n",
    "            \"province_scoli\",\n",
    "        ]\n",
    "    ]\n",
    ")\n",
    "\n",
    "# # Split train test data\n",
    "# X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "#     X, Y, test_size=0.20, random_state=42\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98727283",
   "metadata": {},
   "source": [
    "### Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44abf208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_1.summary()=<class 'statsmodels.iolib.summary.Summary'>\n",
      "\"\"\"\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:              price_log   R-squared:                       0.414\n",
      "Model:                            OLS   Adj. R-squared:                  0.414\n",
      "Method:                 Least Squares   F-statistic:                     1499.\n",
      "Date:                Fri, 11 Apr 2025   Prob (F-statistic):               0.00\n",
      "Time:                        13:52:14   Log-Likelihood:                -11187.\n",
      "No. Observations:               10616   AIC:                         2.239e+04\n",
      "Df Residuals:                   10610   BIC:                         2.243e+04\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=======================================================================================\n",
      "                          coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------\n",
      "const                   4.0794      0.220     18.530      0.000       3.648       4.511\n",
      "age_log                -0.3825      0.009    -40.379      0.000      -0.401      -0.364\n",
      "mileage_log            -0.0385      0.005     -7.189      0.000      -0.049      -0.028\n",
      "origin_multiplier       0.0012      0.008      0.156      0.876      -0.014       0.017\n",
      "model_ref_price_log     0.6460      0.010     63.473      0.000       0.626       0.666\n",
      "province_scoli         -0.0005      0.002     -0.263      0.792      -0.004       0.003\n",
      "==============================================================================\n",
      "Omnibus:                      310.020   Durbin-Watson:                   1.949\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              803.329\n",
      "Skew:                          -0.041   Prob(JB):                    3.62e-175\n",
      "Kurtosis:                       4.345   Cond. No.                     3.18e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 3.18e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "\"\"\"\n"
     ]
    }
   ],
   "source": [
    "model_1 = sm.OLS(Y, X1).fit()\n",
    "print(f\"{model_1.summary()=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99fd052c",
   "metadata": {},
   "source": [
    "## 4.1.2. Improve model accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7418af61",
   "metadata": {},
   "source": [
    "### Remove weak predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "caaace77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_2.summary()=<class 'statsmodels.iolib.summary.Summary'>\n",
      "\"\"\"\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:              price_log   R-squared:                       0.414\n",
      "Model:                            OLS   Adj. R-squared:                  0.414\n",
      "Method:                 Least Squares   F-statistic:                     1874.\n",
      "Date:                Fri, 11 Apr 2025   Prob (F-statistic):               0.00\n",
      "Time:                        13:52:14   Log-Likelihood:                -11187.\n",
      "No. Observations:               10616   AIC:                         2.238e+04\n",
      "Df Residuals:                   10611   BIC:                         2.242e+04\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=======================================================================================\n",
      "                          coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------\n",
      "const                   4.0320      0.127     31.865      0.000       3.784       4.280\n",
      "age_log                -0.3826      0.009    -40.422      0.000      -0.401      -0.364\n",
      "mileage_log            -0.0385      0.005     -7.185      0.000      -0.049      -0.028\n",
      "origin_multiplier       0.0014      0.008      0.174      0.862      -0.014       0.017\n",
      "model_ref_price_log     0.6460      0.010     63.476      0.000       0.626       0.666\n",
      "==============================================================================\n",
      "Omnibus:                      310.032   Durbin-Watson:                   1.949\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              803.369\n",
      "Skew:                          -0.042   Prob(JB):                    3.55e-175\n",
      "Kurtosis:                       4.345   Cond. No.                         285.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "\"\"\"\n"
     ]
    }
   ],
   "source": [
    "X2 = sm.add_constant(\n",
    "    data=df_filter[\n",
    "        [\n",
    "            \"age_log\",\n",
    "            \"mileage_log\",\n",
    "            \"origin_multiplier\",\n",
    "            \"model_ref_price_log\",\n",
    "            # \"province_scoli\",\n",
    "        ]\n",
    "    ]\n",
    ")\n",
    "model_2 = sm.OLS(Y, X2).fit()\n",
    "print(f\"{model_2.summary()=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25ea714",
   "metadata": {},
   "source": [
    "### Analyze influential outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744adaeb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bec75e25",
   "metadata": {},
   "source": [
    "### Final result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
